---
title: "Delta - lognormal Red Grouper"
author: "Adam Kemberling"
date: "October 15, 2018"
output:
  tufte::tufte_html: default
  tufte::tufte_handout: default
  toc: TRUE
  toc_float: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Delta Log-normal Index Template

This is an R Markdown document for matching the delta lognormal procedure and outputs from SAS to R/Rstudio. The overall goal is to functionalize the workthrough, with options for data type and model type so that ultimately a new dataset can be droppped in and with a few setting changes a consistent output will be generated


```{r echo=FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
library(haven)
library(magrittr)
library(DT)
library(knitr)
library(lsmeans)
library(car)
library(kableExtra)

#Set Working Directory to where data is stored
setwd("D:/SASwork/Red Grouper Data and Code for AK/Walter")
MyData <- read_sas("Groundfish/Data/final.sas7bdat")

#load bias correction function
source("Y:/Adam Kemberling/FunctionLibrary/LoBiasCorrectionFunction.R")

#Load functions for lognormal histogram of residuals and qqplot
source("Y:/Adam Kemberling/FunctionLibrary/Lognormal_diagnostics.R")

#Load function for joining models together and incorporating bias correction
source("Y:/Adam Kemberling/FunctionLibrary/dlnorm_lomethod_lsmeans.R")

#Format ggplot for rest of document
theme_set(theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()))

```

## Filter Options

Ideally the first chunk of code here would be the only edits to the template that would need to be made when changing between species, selecting what years to run, and eliminating any stat zones where catches do not occur.     


These can be printed if desired by setting echo = TRUE.

```{r analysis options, echo = FALSE, warning = FALSE, message = FALSE}
#Insert any code that would subset the dataset for any reason
species <- "Red Grouper"             #Target species
ystart <- "2009"                     #Start Year
yend <- "2017"                       #End Year
season_select <- "Summer"            #Season subsetting control
year_column <- "YEAR"

#Rename catch/cpue column to something universal to template
cpue_column <- "N3"                 #Column containing catch/cpue data
MyData <- MyData %>% rename(cpue_dat = paste(cpue_column))


#Need to rename year_column to be exactly "Year"
MyData <- MyData %>% rename(Year = paste(year_column))

#create title from selections
#p_title <- str_c("SEAMAP Summer Groundfish", species, region_select, str_c(ystart,yend, sep = "-"), sep = " ")


#Select column names of factors used in analysis
fact_list <- c("STAT_ZONE", "TOD", "Year", "sponge") #will be used to set formatting for summary tables with if statements
con_vars <- c("DEPTH")

#make vector of survey years for plot scales
ynames <- lubridate::year(seq.Date(as.Date(ystart, "%Y"), as.Date(yend, "%Y"), by = "year"))
ynames <- as.character(ynames)

```

## Derived Value Calculations

This chunk of code is for the calculation of any derived values, and for subsetting the dataset using the filter options stated above.     

These can be printed if desired.


## Full Model Dataset

Here the dataset is added as an interactive table for ease of viewing, for verification that the dataset is contains the correct data for the model. All filtering and subsetting has been done prior to this, so all data here is used for the model.Columns can be sorted by clicking the header for quick checks on the highest/lowest values.

```{r derived values and subsetting, echo = FALSE, message = FALSE, warning = FALSE}


#Make any changes to dataset, and calculate any derived values here
MyData %<>% dplyr::filter(STAT_ZONE != 1,
                        STAT_ZONE <= 8,
                        Year >= as.numeric(ystart),
                        Year <= as.numeric(yend),
                        SEASON == season_select) %>% 
  mutate(sponge = ifelse(W4 == 0, 0, 1),
         sponge = ifelse(W4 >= 50, 2, sponge),
         sponge = factor(sponge),
         success = ifelse(cpue_dat > 0, 1, 0),
         lgcpue = ifelse(cpue_dat > 0, log(cpue_dat), NA))



#get counts by year
SamplesByYear <- as.data.frame( group_by(MyData, Year, add=FALSE) %>% 
                                  summarise (
                                    N = n(),
                                    NominalPPOS = mean(success)) %>% 
                                  rename(Year_f = Year)
)



datatable(MyData, 
          options = list(pageLength = 5,
                         scrollX = T), 
          caption = "Model Dataset",
          width = "700px")

```



## Data Summary

rows for each factor level, with summary statistics on how frequently catches occur and the average cpue.

```{r pressure, echo=FALSE, warning = FALSE, message = FALSE}


#Loop through factors names in fact_list and create a table of observations
for (i in 1:length(fact_list)) {
  
  t1 <- MyData %>%  group_by(.dots = fact_list[1]) %>% 
    dplyr::summarise(N_OBS = n(),
                     N_PP = sum((cpue_dat > 0) == TRUE, na.rm = T),
                     PP_OBS = N_PP/N_OBS,
                     MEAN_CPUE = mean(cpue_dat, na.rm = T))%>% 
    mutate(Factor = rep(fact_list[1], length(unique(fact_list[1])))) %>% 
    rename(Level = fact_list[1]) %>% 
    mutate(Level = as.character(Level)) %>%
    select(Factor, Level, everything())
  
  
  if(length(fact_list > 1)) {
    fact_2 <- MyData %>%  group_by(.dots = fact_list[2]) %>% 
      dplyr::summarise(N_OBS = n(),
                       N_PP = sum((cpue_dat > 0) == TRUE, na.rm = T),
                       PP_OBS = N_PP/N_OBS,
                       MEAN_CPUE = mean(cpue_dat, na.rm = T))%>% 
      mutate(Factor = rep(fact_list[2], length(unique(fact_list[2])))) %>% 
      rename(Level = fact_list[2]) %>% 
      mutate(Level = as.character(Level)) %>%
      select(Factor, Level, everything())
    
    t1 <- bind_rows(t1, fact_2) 
  }
  
  if(length(fact_list > 2)) {
    
    fact_3 <- MyData %>%  group_by(.dots = fact_list[3]) %>% 
      dplyr::summarise(N_OBS = n(),
                       N_PP = sum((cpue_dat > 0) == TRUE, na.rm = T),
                       PP_OBS = N_PP/N_OBS,
                       MEAN_CPUE = mean(cpue_dat, na.rm = T))%>% 
      mutate(Factor = rep(fact_list[3], length(unique(fact_list[3])))) %>% 
      rename(Level = fact_list[3]) %>% 
      mutate(Level = as.character(Level)) %>%
      select(Factor, Level, everything())
    
    t1 <- bind_rows(t1, fact_3)
  }
  
  if(length(fact_list > 3)) {
    fact_4 <-MyData %>%  group_by(.dots = fact_list[4]) %>% 
      dplyr::summarise(N_OBS = n(),
                       N_PP = sum((cpue_dat > 0) == TRUE, na.rm = T),
                       PP_OBS = N_PP/N_OBS,
                       MEAN_CPUE = mean(cpue_dat, na.rm = T))%>% 
      mutate(Factor = rep(fact_list[4], length(unique(fact_list[4])))) %>% 
      rename(Level = fact_list[4]) %>% 
      mutate(Level = as.character(Level)) %>%
      select(Factor, Level, everything())
    
    t1 <- bind_rows(t1, fact_4)
  }
  
}




kable(t1)
rm(t1)

```


## Descriptive Statistics of Observed Data


### Figure 1. CPUE timeline
```{r, echo = FALSE, warning = FALSE, message = FALSE}
MyData %>% 
  group_by(Year) %>% 
  summarise(MEAN_CPUE = mean(cpue_dat)) %>% 
  ggplot(aes(Year, MEAN_CPUE)) + 
  geom_line(aes(group = 1)) +
  geom_point() +
  ylim(0,3) + 
  scale_x_discrete(limits = c(as.numeric(ystart:yend)), labels = ynames) + 
  xlab("Year") +
  ylab("Observed CPUE")
```


### Figure 2. Observed proportion positive timeline
```{r, echo = FALSE, warning = FALSE, message = FALSE}
MyData %>% 
  group_by(Year) %>% 
  summarise(obpos = mean(success)) %>% 
  ggplot(aes(Year, obpos)) + 
  geom_line(aes(group = 1)) + 
  geom_point() +
  scale_x_discrete(limits = c(as.numeric(ystart:yend)), labels = ynames) + 
  xlab("Year") +
  ylab("Observed Proportion Positive Catch") + 
  ylim(c(0.15,0.5))
```

### Figure 3. Frequency distribution log CPUE of positive catch by year
```{r, echo = FALSE, warning = FALSE, message = FALSE}
#Make a positive catch subset
pos_data <- MyData %>% filter(success == 1)

pos_data %>%  ggplot(aes(x = lgcpue)) + 
  geom_histogram(aes(y = stat(density)), bins = 6, fill = "gray80", color = "gray20") +
  stat_function(
    data = filter(MyData, success == 1),
    fun = dnorm, 
    args = list(mean = mean(MyData$lgcpue, na.rm = T), sd = sd(MyData$lgcpue, na.rm = T)),
    col = 'gray20') + 
  ylab("Percent") #+ facet_wrap(~Year)



t2 <- data.frame(Parameter = c("Mean", " Std Dev"), Symbol = c("Mu", "Sigma"), Estimation = c(mean(MyData$lgcpue, na.rm = T), sd(MyData$lgcpue, na.rm = T)))
kable(t2)

rm(t2)

```

### figure 4. Proportion positive catches by year and stat Zone

```{r, echo = FALSE, warning = FALSE, message = FALSE}
MyData %>% group_by(.dots = fact_list) %>% 
  summarise(`Percent Positive` = mean(success)) %>% 
  ggplot(aes(x = `Percent Positive`)) + 
  geom_histogram(aes(y = stat(density)), bins = 10, fill = "gray80", color = "gray20") 

MyData %>% group_by(.dots = fact_list) %>% summarise(N_Obs = n(),
                                      `Percent Positive` = mean(success),
                                      `Std Dev` = sd(success)) %>% 
  datatable(options = list(pageLength = 8))
  # kable() %>%
  # kable_styling() %>%
  # scroll_box(width = "80%", height = "200px")
```

*****

# Model Setups and Summaries

## Binomial glm() on proportion positive

```{r binomial model, echo = FALSE, warning = FALSE, message = FALSE}
#Set contrasts to match SAS
options(contrast=c("contr.SAS", "contr.poly"))
options(contrasts=c("contr.SAS", "contr.poly"))


# #Old code
# MyData <- MyData %>% 
#   mutate(Year_f = factor(Year),
#          Zone_f = factor(STAT_ZONE),
#          Sponge_f = factor(sponge))
# 
# m1 <- glm(success ~ Year_f + Zone_f + Sponge_f + DEPTH,
#           data = MyData,
#           family = quasibinomial(link = "logit"))



#Setup factors for the model automatically
mod_factors <- MyData %>% select(one_of(fact_list))                     #select the columns of interest
colnames(mod_factors) <- lapply(colnames(mod_factors), function(x) paste(x, "_f", sep = ""))  #rename them
mod_factors <- data.frame(sapply(mod_factors, factor))                  #change them to factors


#Add them as new columns to MyData
MyData <- bind_cols(MyData, mod_factors)
pos_data <- filter(MyData, success == 1)


#Set up function call automatically from mod_factors and con_vars
b <- paste(colnames(mod_factors), collapse =" + ")                      #Paste the factors separated by a +
b <- paste(b, "+", paste(con_vars, collapse = " + "))       #Do the same for any continuous variables
b <- paste("success ~ ", b, sep = "")                       #Add the response to it
b_form <- as.formula(b)                                     #coerce to a formula


#Write the model
m1 <- glm(b_form, 
          data = MyData, 
          family = quasibinomial(link = "logit"))


#Print the model Formula
m1$call

#Print the Coefficient values in a table
#kable(m1$coefficients)

#examine type III anova with car
Anova(m1, type=3)

#equamine reference grid for m1
#ref.grid(m1)

```

## Lognormal glm on positive catches

```{r lognormal model, echo = FALSE, warning = FALSE, message = FALSE}
#Make a positive catch subset
pos_data <- MyData %>% filter(success == 1)

#And a year summary of the mean catch
pos_timeline <- pos_data %>% group_by(Year_f) %>% summarise(obcppos = mean(cpue_dat))

# # Old Code
# m2 <- glm(lgcpue ~ Year_f + Zone_f + Sponge_f + DEPTH, data = pos_data, family = "gaussian")


#Set up function call automatically from mod_factors and con_vars
b <- paste(colnames(mod_factors), collapse =" + ")                      #Paste the factors separated by a +
b <- paste(b, "+", paste(con_vars, collapse = " + "))       #Do the same for any continuous variables
b <- paste("lgcpue ~ ", b, sep = "")                       #Add the response to it
ln_form <- as.formula(b)   


# Write/execute model
m2 <- glm(ln_form, 
          data = pos_data, 
          family = "gaussian")



#Print model call
m2$call

#Put coefficient estimates in a table
#kable(m2$coefficients)


ln_hist(ln_model = m2)
ln_qqplot(ln_model = m2)




```

## Bias-corrected backtransformation


```{r lsmeans sourced from a function, echo = FALSE, message=FALSE, warning=FALSE}

estimate <- dlnorm_lo_method(bin_model = m1, Ln_model = m2)


#Pull out important columns
short <- estimate %>% select(Year_f, Index, LCI, UCI, StdIndex, CV_Index, StdLCI, StdUCI)
DLNIndex <- merge(SamplesByYear,short, by = "Year_f")
rm(short)

#add missing years
YearRange <- as.data.frame(seq(min(as.numeric(DLNIndex$Year_f)), max(as.numeric(DLNIndex$Year_f))))
names(YearRange) <- c("Year_f")
DLNIndexMissing <- merge(YearRange,DLNIndex,by="Year_f",all.x=T)
kable(DLNIndexMissing)

#Make dataframe of the observed cPUE
obs_df <- MyData %>% group_by(Year) %>% dplyr::summarise(N_OBS = n(),
                                      N_PP = sum((cpue_dat > 0) == TRUE, na.rm = T),
                                      PP_OBS = N_PP/N_OBS,
                                      MEAN_CPUE = mean(cpue_dat, na.rm = T))

```



## Observed and Standardized CPUE (95% CI)

```{r, echo = FALSE, message = FALSE, warning=FALSE}

estimate <- estimate %>% mutate(
  Year_n = as.numeric(as.character(Year_f)))


overall_meancpue <- mean(MyData$cpue_dat)
obscpue_df <- MyData %>% group_by(Year_f) %>%  summarise(ob_scpue = mean(cpue_dat)/overall_meancpue) %>% 
  mutate(Year_n = as.numeric(as.character(Year_f)))

ggplot(data = DLNIndex, aes(Year_f, StdIndex)) + 
  geom_line(color = "blue") +
  geom_point(color = "blue") +
  geom_line(aes(Year_f, StdUCI, group = 1),color = "blue", lty = 2) +
  geom_line(aes(Year_f, StdLCI, group = 1),color = "blue", lty = 2) +
  geom_line(data = obscpue_df, aes(Year_n, ob_scpue, group = 1), color = "red") + 
  geom_point(data = obscpue_df, aes(Year_n, ob_scpue, group = 1), color = "red") + 
  scale_x_discrete(limits = c(as.numeric(ynames)),  labels = ynames) + 
  ylim(0,4) +xlab("Year") + ylab("Estimated CPUE")




```

## Diagnostic Plot 1. Obs vs Pred Proportion Positive

```{r, echo = FALSE, message = FALSE, warning = TRUE}

obppos <- MyData %>% group_by(Year_f) %>% summarise(n = n(),
                                        obppos = sum(success)/n) 

ggplot(estimate, (aes(Year_f, LSM_prob))) +
  geom_line(aes(group = 1), color = "blue", lty = 2) + 
  geom_point(color = "blue") +
  geom_line(data = obppos, aes(Year_f, obppos, group = 1), color = "red") + 
  geom_point(data = obppos, aes(Year_f, obppos), color = "red") +
  ylim(0,0.4) + 
  xlab("Year") +
  ylab("Proportion of Samples Catch > 0")


```

## Diagnostic Plot 2. Obs vs Pred CPUE of Positive Only Data

```{r, echo = FALSE, message = FALSE, warning = TRUE}

estimate$bccpue <- estimate$LSM_bcpos * estimate$gc_pos

ggplot(pos_timeline, aes(Year_f, obcppos)) +
  geom_line(aes(group = 1),color = "red") +
  geom_point(color = "red") +
  geom_line(data = estimate, aes(Year_f, bccpue, group = 1), lty = 2, color = "blue") +
  geom_point(data = estimate, aes(Year_f, bccpue), color = "blue") +
  ylim(0,9) +
  scale_y_continuous(limits =c(0,9), breaks = 0:9) +
  xlab("Year") +
  ylab("obcppos")

```

## Diagnostic Plot 3. Obs vs Pred CPUE input units 

```{r, echo = FALSE, message = FALSE, warning = TRUE}
ggplot(data = obs_df, aes(Year, MEAN_CPUE)) +
  geom_line(color = "red")  +
  geom_line(data = DLNIndex, aes(Year_f, Index), color = "blue", lty = 2) +
  geom_point(color = "red")  +
  geom_point(data = DLNIndex, aes(Year_f, Index), color = "blue") +
  scale_x_discrete(limits = c(as.numeric(ystart:yend)), labels = ynames) + 
  xlab("Year") + ylab("Estimated CPUE")
```


